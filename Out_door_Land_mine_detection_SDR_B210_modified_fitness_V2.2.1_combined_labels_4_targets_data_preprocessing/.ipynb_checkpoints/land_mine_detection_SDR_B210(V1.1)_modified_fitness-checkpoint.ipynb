{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the features by using the standard scaler\n",
    "# algorithm parameter:\n",
    "#      100 total trees in RF\n",
    "#      select 10 trees by GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library for GA\n",
    "import random\n",
    "\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "# library for RF\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from seaborn import violinplot\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_data = pd.read_excel('./spectrum_data/Nothing_Mine_Rock_EmptyCan_Combined_Labels.xlsx',  sep = ',', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Signal_Path</th>\n",
       "      <th>Frequency_0</th>\n",
       "      <th>Frequency_0dot32541</th>\n",
       "      <th>Frequency_0dot65083</th>\n",
       "      <th>Frequency_0dot97624</th>\n",
       "      <th>Frequency_1dot3017</th>\n",
       "      <th>Frequency_1dot6271</th>\n",
       "      <th>Frequency_1dot9525</th>\n",
       "      <th>Frequency_2dot2779</th>\n",
       "      <th>Frequency_2dot6033</th>\n",
       "      <th>...</th>\n",
       "      <th>Frequency_497dot234</th>\n",
       "      <th>Frequency_497dot5594</th>\n",
       "      <th>Frequency_497dot8848</th>\n",
       "      <th>Frequency_498dot2102</th>\n",
       "      <th>Frequency_498dot5356</th>\n",
       "      <th>Frequency_498dot861</th>\n",
       "      <th>Frequency_499dot1865</th>\n",
       "      <th>Frequency_499dot5119</th>\n",
       "      <th>Frequency_499dot8373</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.459259</td>\n",
       "      <td>-4.532056</td>\n",
       "      <td>-32.680765</td>\n",
       "      <td>-34.772452</td>\n",
       "      <td>-37.362220</td>\n",
       "      <td>-41.463815</td>\n",
       "      <td>-41.809600</td>\n",
       "      <td>-41.411157</td>\n",
       "      <td>-42.444672</td>\n",
       "      <td>...</td>\n",
       "      <td>-92.727267</td>\n",
       "      <td>-94.206407</td>\n",
       "      <td>-95.049497</td>\n",
       "      <td>-92.151649</td>\n",
       "      <td>-94.120509</td>\n",
       "      <td>-95.140720</td>\n",
       "      <td>-91.976042</td>\n",
       "      <td>-88.533568</td>\n",
       "      <td>-91.717852</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.928653</td>\n",
       "      <td>1.957394</td>\n",
       "      <td>-35.392737</td>\n",
       "      <td>-42.128736</td>\n",
       "      <td>-46.621402</td>\n",
       "      <td>-53.255708</td>\n",
       "      <td>-56.017699</td>\n",
       "      <td>-59.087885</td>\n",
       "      <td>-62.249034</td>\n",
       "      <td>...</td>\n",
       "      <td>-88.354186</td>\n",
       "      <td>-88.465816</td>\n",
       "      <td>-85.997244</td>\n",
       "      <td>-87.914434</td>\n",
       "      <td>-88.387158</td>\n",
       "      <td>-89.374889</td>\n",
       "      <td>-87.190449</td>\n",
       "      <td>-88.074054</td>\n",
       "      <td>-85.246747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5.429769</td>\n",
       "      <td>2.402802</td>\n",
       "      <td>-39.912158</td>\n",
       "      <td>-40.833904</td>\n",
       "      <td>-43.269220</td>\n",
       "      <td>-44.225699</td>\n",
       "      <td>-43.763521</td>\n",
       "      <td>-44.645556</td>\n",
       "      <td>-46.069485</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.576766</td>\n",
       "      <td>-92.467630</td>\n",
       "      <td>-89.857615</td>\n",
       "      <td>-86.389981</td>\n",
       "      <td>-85.861711</td>\n",
       "      <td>-88.080618</td>\n",
       "      <td>-88.199254</td>\n",
       "      <td>-89.362906</td>\n",
       "      <td>-92.505462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-8.860418</td>\n",
       "      <td>-11.892214</td>\n",
       "      <td>-40.604265</td>\n",
       "      <td>-41.491205</td>\n",
       "      <td>-46.728661</td>\n",
       "      <td>-45.278651</td>\n",
       "      <td>-46.840303</td>\n",
       "      <td>-48.153704</td>\n",
       "      <td>-48.827305</td>\n",
       "      <td>...</td>\n",
       "      <td>-88.342649</td>\n",
       "      <td>-90.868922</td>\n",
       "      <td>-88.491640</td>\n",
       "      <td>-89.537515</td>\n",
       "      <td>-89.388839</td>\n",
       "      <td>-90.235332</td>\n",
       "      <td>-90.477474</td>\n",
       "      <td>-91.199705</td>\n",
       "      <td>-89.209511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-14.143644</td>\n",
       "      <td>-17.023779</td>\n",
       "      <td>-34.837263</td>\n",
       "      <td>-43.262198</td>\n",
       "      <td>-43.991594</td>\n",
       "      <td>-47.693121</td>\n",
       "      <td>-48.950286</td>\n",
       "      <td>-45.364605</td>\n",
       "      <td>-46.008724</td>\n",
       "      <td>...</td>\n",
       "      <td>-90.700178</td>\n",
       "      <td>-93.163671</td>\n",
       "      <td>-93.431828</td>\n",
       "      <td>-90.653285</td>\n",
       "      <td>-93.611234</td>\n",
       "      <td>-90.997471</td>\n",
       "      <td>-89.479312</td>\n",
       "      <td>-87.478921</td>\n",
       "      <td>-90.607241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1539 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Signal_Path  Frequency_0  Frequency_0dot32541  Frequency_0dot65083  \\\n",
       "0            1    -1.459259            -4.532056           -32.680765   \n",
       "1            1     4.928653             1.957394           -35.392737   \n",
       "2            1     5.429769             2.402802           -39.912158   \n",
       "3            1    -8.860418           -11.892214           -40.604265   \n",
       "4            1   -14.143644           -17.023779           -34.837263   \n",
       "\n",
       "   Frequency_0dot97624  Frequency_1dot3017  Frequency_1dot6271  \\\n",
       "0           -34.772452          -37.362220          -41.463815   \n",
       "1           -42.128736          -46.621402          -53.255708   \n",
       "2           -40.833904          -43.269220          -44.225699   \n",
       "3           -41.491205          -46.728661          -45.278651   \n",
       "4           -43.262198          -43.991594          -47.693121   \n",
       "\n",
       "   Frequency_1dot9525  Frequency_2dot2779  Frequency_2dot6033  ...  \\\n",
       "0          -41.809600          -41.411157          -42.444672  ...   \n",
       "1          -56.017699          -59.087885          -62.249034  ...   \n",
       "2          -43.763521          -44.645556          -46.069485  ...   \n",
       "3          -46.840303          -48.153704          -48.827305  ...   \n",
       "4          -48.950286          -45.364605          -46.008724  ...   \n",
       "\n",
       "   Frequency_497dot234  Frequency_497dot5594  Frequency_497dot8848  \\\n",
       "0           -92.727267            -94.206407            -95.049497   \n",
       "1           -88.354186            -88.465816            -85.997244   \n",
       "2           -87.576766            -92.467630            -89.857615   \n",
       "3           -88.342649            -90.868922            -88.491640   \n",
       "4           -90.700178            -93.163671            -93.431828   \n",
       "\n",
       "   Frequency_498dot2102  Frequency_498dot5356  Frequency_498dot861  \\\n",
       "0            -92.151649            -94.120509           -95.140720   \n",
       "1            -87.914434            -88.387158           -89.374889   \n",
       "2            -86.389981            -85.861711           -88.080618   \n",
       "3            -89.537515            -89.388839           -90.235332   \n",
       "4            -90.653285            -93.611234           -90.997471   \n",
       "\n",
       "   Frequency_499dot1865  Frequency_499dot5119  Frequency_499dot8373  Label  \n",
       "0            -91.976042            -88.533568            -91.717852      1  \n",
       "1            -87.190449            -88.074054            -85.246747      1  \n",
       "2            -88.199254            -89.362906            -92.505462      1  \n",
       "3            -90.477474            -91.199705            -89.209511      1  \n",
       "4            -89.479312            -87.478921            -90.607241      1  \n",
       "\n",
       "[5 rows x 1539 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrum_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set algorithm parameters\n",
    "\n",
    "def run_GA(NUM_TREES, IND_SIZE, POP_SIZE, CX_RATE = 0.8):\n",
    "    \"\"\"\n",
    "    NUM_TREES is the number of trees the random forest model pro\n",
    "    \"\"\"    \n",
    "    MUTATE_RATE = 1.0/IND_SIZE \n",
    "    \n",
    "    \n",
    "    \n",
    "    # prepare data\n",
    "   \n",
    "    raw = spectrum_data.values\n",
    "\n",
    "    X = raw[:, 0:1538]\n",
    "    y = raw[:, 1538]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=random.randint(0,5000))\n",
    "    \n",
    "    # Feature Scaling\n",
    "    end = 1539\n",
    "    scaler = StandardScaler()\n",
    "    X_train[:, 1:end] = scaler.fit_transform(X_train[:, 1:end])   # Fit to data, then transform it. Fit means Compute the mean and std to be used for later scaling.\n",
    "    X_test[:, 1:end] = scaler.transform(X_test[:, 1:end]) # Perform standardization by centering and scaling\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators= NUM_TREES) # create a random forest with NUM_TREES = 20 \n",
    "    model.fit(X_train, y_train) # train the model\n",
    "    estimators = model.estimators_ # get all the trees\n",
    "    \n",
    "    # implement individual\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "    # implement functions for initialize population and create individual\n",
    "    toolbox = base.Toolbox() # create a toolbox of operators for our GA algorithm\n",
    "    toolbox.register(\"indices\", random.sample, range(NUM_TREES), NUM_TREES) # this is a helper function for creating\n",
    "                                                                            # each individual\n",
    "    toolbox.register(\"individual\", tools.initIterate, creator.Individual,   # this is the function for creating an \n",
    "                     toolbox.indices)                                       # individual\n",
    "\n",
    "\n",
    "    #toolbox.individual()  # a test \n",
    "\n",
    "    # implement function for creating a population\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual, n = POP_SIZE)\n",
    "\n",
    "    #toolbox.population()  # a test\n",
    "    \n",
    "    def sub_rf_predict(sub_rf, X_test):\n",
    "        \"\"\"\n",
    "        return the predict result using the sub_rf and X_test data;\n",
    "        the rule is that predict result(labels) with the maximum number of votes wins.\n",
    "        \"\"\"\n",
    "        predict_results = []\n",
    "        for tree in sub_rf:\n",
    "            prediction = tree.predict(X_test)\n",
    "            # record prediction result for a tree\n",
    "            predict_results.append(prediction)\n",
    "\n",
    "        # compute the vote_result, i.e. the final result\n",
    "        y_predict = [0]*len(X_test)\n",
    "        for idx in range(len(X_test)):\n",
    "            # for each test data\n",
    "            # create a vote result\n",
    "            v_result = vote_result()\n",
    "            for predict_tree in predict_results:\n",
    "                v_result[predict_tree[idx]] += 1\n",
    "\n",
    "            # final result\n",
    "            y_predict[idx] = keywithmaxval(v_result)\n",
    "\n",
    "        return  np.array(y_predict, dtype = float)\n",
    "\n",
    "    # helper function\n",
    "    y_set = set(y_test).union(y_train)\n",
    "    def vote_result():\n",
    "        result = {}\n",
    "        for k in y_set:\n",
    "            result[k] = 0\n",
    "        return result\n",
    "\n",
    "    def keywithmaxval(d):\n",
    "        \"\"\" a) create a list of the dict's keys and values; \n",
    "        b) return the key with the max value\"\"\"  \n",
    "        v=list(d.values())\n",
    "        k=list(d.keys())\n",
    "        return k[v.index(max(v))]\n",
    "    \n",
    "    \n",
    "    #  modified fitness function\n",
    "    def evaluate(individual):\n",
    "        # return the accuracy on the test data\n",
    "        sub_random_forest = []\n",
    "        for tree_idx in individual[0: IND_SIZE]:\n",
    "            sub_random_forest.append(estimators[tree_idx])\n",
    "\n",
    "        predict_sub_trees = sub_rf_predict(sub_random_forest, X_test)\n",
    "        # print(predict_sub_trees.__repr__())\n",
    "        # score = precision_score(y_test, predict_sub_trees, average = 'macro')\n",
    "        cf_matrix = evaluate_confusion_matrix(individual)\n",
    "        \n",
    "        pseudo_acc_case_rate = cf_matrix[1, 1] / np.sum(cf_matrix)\n",
    "        bad_case_rate = (cf_matrix[1, 0] + cf_matrix[1, 2]) / np.sum(cf_matrix)\n",
    "        undesired_case_rate = (cf_matrix[0, 1] + cf_matrix[2, 1]) / np.sum(cf_matrix)\n",
    "        \n",
    "        # give accuracy more weight\n",
    "        score = 0.4 * pseudo_acc_case_rate - 0.4 * bad_case_rate - 0.2 * undesired_case_rate\n",
    "        return  score,  # must return an tuple!!!!\n",
    "    \n",
    "    def evaluate_confusion_matrix(individual):\n",
    "        # return the confusion matrix of a model\n",
    "        sub_random_forest = []\n",
    "        for tree_idx in individual[0: IND_SIZE]:\n",
    "            sub_random_forest.append(estimators[tree_idx])\n",
    "\n",
    "        predict_sub_trees = sub_rf_predict(sub_random_forest, X_test)\n",
    "        cf_matrix = confusion_matrix(y_test, predict_sub_trees)\n",
    "        return  cf_matrix \n",
    "\n",
    "    \n",
    "    \n",
    "    # implement mutation operator\n",
    "    mutation_op = tools.mutShuffleIndexes\n",
    "    \n",
    "    \n",
    "    # implement crossover\n",
    "    def crossover_op(ind1, ind2):\n",
    "        # only cross over the first IND_SIZE elements in the individual in place\n",
    "        crossover_idx = random.randint(0, IND_SIZE - 2)\n",
    "        # print(crossover_idx)\n",
    "        temp = toolbox.clone(ind1[crossover_idx + 1: IND_SIZE])\n",
    "        ind1[crossover_idx + 1: IND_SIZE] = ind2[crossover_idx + 1: IND_SIZE]\n",
    "        ind2[crossover_idx + 1: IND_SIZE] = temp\n",
    "        return (ind1, ind2)\n",
    "    \n",
    "    # implement selection operator\n",
    "    selection_op = tools.selTournament\n",
    "    \n",
    "    \n",
    "    # register everything in our toolbox\n",
    "    toolbox.register(\"mate\", crossover_op)\n",
    "    toolbox.register(\"mutate\", mutation_op, indpb = MUTATE_RATE)\n",
    "    toolbox.register(\"select\", selection_op, tournsize=3)\n",
    "    toolbox.register(\"evaluate\", evaluate)\n",
    "    \n",
    "    \n",
    "    h_fame = tools.HallOfFame(100) # keep track of the first 100 best individuals and store them in h_fame\n",
    "\n",
    "    pop = toolbox.population()\n",
    "    final_pop = algorithms.eaSimple(pop, toolbox, cxpb = CX_RATE, mutpb=MUTATE_RATE, ngen=1000, \n",
    "                                    stats = None, halloffame = h_fame, verbose = False)\n",
    "    \n",
    "    # accuracy_of_the_best_individual = evaluate(h_fame[0])\n",
    "    # accuracy_of_the_whole_trees_model = accuracy_score(y_test, model.predict(X_test))\n",
    "    cf_matrix_RF_model = confusion_matrix(y_test, model.predict(X_test))\n",
    "    cf_matrix_GA_RF_model = evaluate_confusion_matrix(h_fame[0])\n",
    "    \n",
    "    return cf_matrix_GA_RF_model, cf_matrix_RF_model, evaluate_confusion_matrix, h_fame, estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_model_performance(C):\n",
    "    \"\"\"\n",
    "    C is a confusion matrix\n",
    "    accuracy, sensitivity, specificity: the higher the better\n",
    "    FP_rate: the lower the better\n",
    "    \n",
    "    Now, only compute accuracy\n",
    "    \"\"\"\n",
    "    accuracy = (C[0,0] + C[1, 1] + C[2, 2]) / np.sum(C)\n",
    "    sensitivity = 0\n",
    "    specificity = 0 \n",
    "    FP_rate = 0\n",
    "    \n",
    "    cf_matrix = C\n",
    "    pseudo_acc_case_rate = cf_matrix[1, 1] / np.sum(cf_matrix)\n",
    "    bad_case_rate = (cf_matrix[1, 0] + cf_matrix[1, 2]) / np.sum(cf_matrix)\n",
    "    undesired_case_rate = (cf_matrix[0, 1] + cf_matrix[2, 1]) / np.sum(cf_matrix)\n",
    "    \n",
    "    left_diag_case_rate = (cf_matrix[0, 0] + cf_matrix[2, 2]) / np.sum(cf_matrix)\n",
    "    right_diag_case_rate = (cf_matrix[0, 2] + cf_matrix[2, 0]) / np.sum(cf_matrix)\n",
    "        # give accuracy more weight\n",
    "    performance = 0.3 * pseudo_acc_case_rate - 0.3 * bad_case_rate - 0.2 * undesired_case_rate + 0.2 * 0.8 * left_diag_case_rate + 0.2 * 0.2 * right_diag_case_rate\n",
    "    \n",
    "    return accuracy, sensitivity, specificity, FP_rate, performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_trees =  100\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "num_trees = 100\n",
    "GA_accuracy_result = []\n",
    "RF_accuracy_result = []\n",
    "\n",
    "GA_sensitivity_result = []\n",
    "RF_sensitivity_result = []\n",
    "\n",
    "GA_specificity_result = []\n",
    "RF_specificity_result = []\n",
    "\n",
    "GA_FP_rate_result = []\n",
    "RF_FP_rate_result = []\n",
    "\n",
    "confusion_matrices_list_GA_RF = []\n",
    "h_fame_list = []\n",
    "GA_RF_model_list = []\n",
    "\n",
    "GA_score_list = []\n",
    "\n",
    "print('num_trees = ', num_trees)\n",
    "for i in range(50):  # run the experiment 300 times\n",
    "    print(i)\n",
    "    cf_matrix_GA_RF_model, cf_matrix_RF_model, evaluate_confusion_matrix, h_fame, estimators = run_GA(num_trees, 10, 30)\n",
    "    \n",
    "    GA_accuracy, GA_sensitivity, GA_specificity, GA_FP_rate, GA_score = measure_model_performance(cf_matrix_GA_RF_model)\n",
    "    RF_accuracy, RF_sensitivity, RF_specificity, RF_FP_rate, RF_score = measure_model_performance(cf_matrix_RF_model)\n",
    "\n",
    "    GA_accuracy_result.append(GA_accuracy)\n",
    "    RF_accuracy_result.append(RF_accuracy)\n",
    "\n",
    "    GA_sensitivity_result.append(GA_sensitivity)\n",
    "    RF_sensitivity_result.append(RF_sensitivity)\n",
    "\n",
    "    GA_specificity_result.append(GA_specificity)\n",
    "    RF_specificity_result.append(RF_specificity)\n",
    "\n",
    "    GA_FP_rate_result.append(GA_FP_rate)\n",
    "    RF_FP_rate_result.append(RF_FP_rate)\n",
    "    \n",
    "    confusion_matrices_list_GA_RF.append(cf_matrix_GA_RF_model)\n",
    "    GA_RF_model_list.append(estimators)\n",
    "    \n",
    "    GA_score_list.append(GA_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result():\n",
    "    print(\"mean accuracy = \",  np.mean(GA_accuracy_result))\n",
    "    print(\"std accuracy = \", np.std(GA_accuracy_result))\n",
    "    print(\"Max accuracy = \", np.max(GA_accuracy_result))\n",
    "    print(\"confusion Matrix for model with max accuracy is \\n\", confusion_matrices_list_GA_RF[np.argmax(GA_accuracy_result)])\n",
    "    print(\"Max score = \", np.max(GA_score_list))\n",
    "    print(\"confusion Matrix for model with max score is \\n\", confusion_matrices_list_GA_RF[np.argmax(GA_score_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
