{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,classification_report, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train/test data\n",
    "\n",
    "# read data\n",
    "spectrum_data = pd.read_excel('./spectrum_data/Nothing_Mine_CEandRock.xlsx',  sep = ',', header = 0)\n",
    "# remove freqs prior to 129\n",
    "spectrum_data_new = spectrum_data.iloc[:, 400:1539]\n",
    "\n",
    "\n",
    "# df.insert(loc=idx, column='A', value=new_col)\n",
    "spectrum_data_new.insert(loc = 0, column = 'Signal Path', value = spectrum_data.iloc[:, 0])\n",
    "raw = spectrum_data_new.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def normalize_score(scores, max_score, min_score):\n",
    "    np_scores = np.array(scores)\n",
    "    return (np_scores - min_score)/(max_score - min_score)\n",
    "\n",
    "def get_score(cf_matrix):\n",
    "    pseudo_acc_case_rate = cf_matrix[1, 1] / np.sum(cf_matrix)\n",
    "    bad_case_rate = (cf_matrix[1, 0] + cf_matrix[1, 2]) / np.sum(cf_matrix)\n",
    "    undesired_case_rate = (cf_matrix[0, 1] + cf_matrix[2, 1]) / np.sum(cf_matrix)\n",
    "\n",
    "    # give accuracy more weight\n",
    "    score = (0.4 * pseudo_acc_case_rate - 0.4 * bad_case_rate - 0.2 * undesired_case_rate) # the max score is 1 and the min score is 0.\n",
    "    return  score\n",
    "\n",
    "\n",
    "max_score = 2/15\n",
    "min_score = -1/5\n",
    "def get_mormalized_score(cf_matrix):\n",
    "    return normalize_score(get_score(cf_matrix), max_score, min_score)\n",
    "\n",
    "def my_score(y_true, y_pred):\n",
    "    cf = confusion_matrix(y_true, y_pred)\n",
    "    return get_mormalized_score(cf)\n",
    "\n",
    "score = make_scorer(my_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_data():\n",
    "    # prepare data\n",
    "    X_0 = raw[0:100, 0:1139]\n",
    "    y_0 = raw[0:100, 1139]\n",
    "\n",
    "    X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(X_0, y_0, test_size=0.25, random_state=random.randint(0,5000))\n",
    "\n",
    "    X_1 = raw[100:200, 0:1139]\n",
    "    y_1 = raw[100:200, 1139]\n",
    "\n",
    "    X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, y_1, test_size=0.25, random_state=random.randint(0,5000))\n",
    "\n",
    "    X_2 = raw[200:300, 0:1139]\n",
    "    y_2 = raw[200:300, 1139]\n",
    "\n",
    "    X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.25, random_state=random.randint(0,5000))\n",
    "\n",
    "    y_test = np.concatenate((y_test_0, y_test_1, y_test_2), axis=0)\n",
    "    y_train = np.concatenate((y_train_0, y_train_1, y_train_2), axis=0)\n",
    "    X_test = np.concatenate((X_test_0, X_test_1, X_test_2), axis=0)\n",
    "    X_train = np.concatenate((X_train_0, X_train_1, X_train_2), axis=0)\n",
    "\n",
    "    # Feature Scaling\n",
    "    end = 1139\n",
    "    scaler = StandardScaler()\n",
    "    X_train[:, 1:end] = scaler.fit_transform(X_train[:, 1:end])   # Fit to data, then transform it. Fit means Compute the mean and std to be used for later scaling.\n",
    "    X_test[:, 1:end] = scaler.transform(X_test[:, 1:end]) # Perform standardization by centering and scaling\n",
    "    \n",
    "    \n",
    "    # grid search a best model\n",
    "    grid = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "    logreg = LogisticRegression()\n",
    "    logreg_cv = GridSearchCV(logreg, grid, cv = 5, scoring = score)\n",
    "    logreg_cv.fit(X_train, y_train)\n",
    "    \n",
    "    # compute scores on test data\n",
    "    return score(logreg_cv, X_test, y_test), confusion_matrix(y_test, logreg_cv.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3919999999999999, array([[ 8, 10,  7],\n",
       "        [ 7, 10,  8],\n",
       "        [ 3,  6, 16]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
