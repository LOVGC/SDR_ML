{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the features by using the standard scaler\n",
    "# remove frequencies prior to 129 Hz\n",
    "\n",
    "# algorithm parameter:\n",
    "#      100 total trees in RF\n",
    "#      select 10 trees by GA\n",
    "#      run 300 tests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Signal Path</th>\n",
       "      <th>Frequency_129dot8405</th>\n",
       "      <th>Frequency_130dot166</th>\n",
       "      <th>Frequency_130dot4914</th>\n",
       "      <th>Frequency_130dot8168</th>\n",
       "      <th>Frequency_131dot1422</th>\n",
       "      <th>Frequency_131dot4676</th>\n",
       "      <th>Frequency_131dot793</th>\n",
       "      <th>Frequency_132dot1185</th>\n",
       "      <th>Frequency_132dot4439</th>\n",
       "      <th>...</th>\n",
       "      <th>Frequency_497dot234</th>\n",
       "      <th>Frequency_497dot5594</th>\n",
       "      <th>Frequency_497dot8848</th>\n",
       "      <th>Frequency_498dot2102</th>\n",
       "      <th>Frequency_498dot5356</th>\n",
       "      <th>Frequency_498dot861</th>\n",
       "      <th>Frequency_499dot1865</th>\n",
       "      <th>Frequency_499dot5119</th>\n",
       "      <th>Frequency_499dot8373</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-82.338222</td>\n",
       "      <td>-84.856415</td>\n",
       "      <td>-84.857809</td>\n",
       "      <td>-83.830094</td>\n",
       "      <td>-85.688775</td>\n",
       "      <td>-83.544618</td>\n",
       "      <td>-83.965124</td>\n",
       "      <td>-85.252199</td>\n",
       "      <td>-84.495197</td>\n",
       "      <td>...</td>\n",
       "      <td>-86.637317</td>\n",
       "      <td>-86.343540</td>\n",
       "      <td>-86.970514</td>\n",
       "      <td>-87.039263</td>\n",
       "      <td>-88.502441</td>\n",
       "      <td>-90.199369</td>\n",
       "      <td>-87.116829</td>\n",
       "      <td>-88.726635</td>\n",
       "      <td>-90.726685</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-88.912104</td>\n",
       "      <td>-88.837733</td>\n",
       "      <td>-89.573053</td>\n",
       "      <td>-90.704677</td>\n",
       "      <td>-87.893270</td>\n",
       "      <td>-87.805782</td>\n",
       "      <td>-86.055104</td>\n",
       "      <td>-87.536184</td>\n",
       "      <td>-92.052088</td>\n",
       "      <td>...</td>\n",
       "      <td>-92.337580</td>\n",
       "      <td>-94.363767</td>\n",
       "      <td>-92.113655</td>\n",
       "      <td>-91.933969</td>\n",
       "      <td>-91.717233</td>\n",
       "      <td>-91.703702</td>\n",
       "      <td>-94.641164</td>\n",
       "      <td>-90.733663</td>\n",
       "      <td>-89.704103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-84.016012</td>\n",
       "      <td>-84.131448</td>\n",
       "      <td>-88.740907</td>\n",
       "      <td>-87.258607</td>\n",
       "      <td>-86.179744</td>\n",
       "      <td>-85.351962</td>\n",
       "      <td>-85.685550</td>\n",
       "      <td>-84.290518</td>\n",
       "      <td>-84.573309</td>\n",
       "      <td>...</td>\n",
       "      <td>-90.403409</td>\n",
       "      <td>-91.020674</td>\n",
       "      <td>-88.187210</td>\n",
       "      <td>-85.616805</td>\n",
       "      <td>-86.914083</td>\n",
       "      <td>-91.192905</td>\n",
       "      <td>-91.401812</td>\n",
       "      <td>-91.905812</td>\n",
       "      <td>-86.226784</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-90.165488</td>\n",
       "      <td>-89.575706</td>\n",
       "      <td>-81.921091</td>\n",
       "      <td>-82.703704</td>\n",
       "      <td>-85.714261</td>\n",
       "      <td>-87.114000</td>\n",
       "      <td>-86.829531</td>\n",
       "      <td>-88.225574</td>\n",
       "      <td>-87.459190</td>\n",
       "      <td>...</td>\n",
       "      <td>-90.557058</td>\n",
       "      <td>-91.756146</td>\n",
       "      <td>-89.087595</td>\n",
       "      <td>-90.093507</td>\n",
       "      <td>-89.855050</td>\n",
       "      <td>-90.758625</td>\n",
       "      <td>-88.137099</td>\n",
       "      <td>-89.833695</td>\n",
       "      <td>-89.888380</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-87.726753</td>\n",
       "      <td>-89.734590</td>\n",
       "      <td>-87.878417</td>\n",
       "      <td>-89.838251</td>\n",
       "      <td>-90.120643</td>\n",
       "      <td>-87.962830</td>\n",
       "      <td>-89.312585</td>\n",
       "      <td>-89.720013</td>\n",
       "      <td>-87.447822</td>\n",
       "      <td>...</td>\n",
       "      <td>-91.405036</td>\n",
       "      <td>-90.592510</td>\n",
       "      <td>-91.839187</td>\n",
       "      <td>-93.906633</td>\n",
       "      <td>-91.387335</td>\n",
       "      <td>-93.815508</td>\n",
       "      <td>-93.235216</td>\n",
       "      <td>-92.409103</td>\n",
       "      <td>-93.528927</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Signal Path  Frequency_129dot8405  Frequency_130dot166  \\\n",
       "0            1            -82.338222           -84.856415   \n",
       "1            1            -88.912104           -88.837733   \n",
       "2            1            -84.016012           -84.131448   \n",
       "3            1            -90.165488           -89.575706   \n",
       "4            1            -87.726753           -89.734590   \n",
       "\n",
       "   Frequency_130dot4914  Frequency_130dot8168  Frequency_131dot1422  \\\n",
       "0            -84.857809            -83.830094            -85.688775   \n",
       "1            -89.573053            -90.704677            -87.893270   \n",
       "2            -88.740907            -87.258607            -86.179744   \n",
       "3            -81.921091            -82.703704            -85.714261   \n",
       "4            -87.878417            -89.838251            -90.120643   \n",
       "\n",
       "   Frequency_131dot4676  Frequency_131dot793  Frequency_132dot1185  \\\n",
       "0            -83.544618           -83.965124            -85.252199   \n",
       "1            -87.805782           -86.055104            -87.536184   \n",
       "2            -85.351962           -85.685550            -84.290518   \n",
       "3            -87.114000           -86.829531            -88.225574   \n",
       "4            -87.962830           -89.312585            -89.720013   \n",
       "\n",
       "   Frequency_132dot4439  ...  Frequency_497dot234  Frequency_497dot5594  \\\n",
       "0            -84.495197  ...           -86.637317            -86.343540   \n",
       "1            -92.052088  ...           -92.337580            -94.363767   \n",
       "2            -84.573309  ...           -90.403409            -91.020674   \n",
       "3            -87.459190  ...           -90.557058            -91.756146   \n",
       "4            -87.447822  ...           -91.405036            -90.592510   \n",
       "\n",
       "   Frequency_497dot8848  Frequency_498dot2102  Frequency_498dot5356  \\\n",
       "0            -86.970514            -87.039263            -88.502441   \n",
       "1            -92.113655            -91.933969            -91.717233   \n",
       "2            -88.187210            -85.616805            -86.914083   \n",
       "3            -89.087595            -90.093507            -89.855050   \n",
       "4            -91.839187            -93.906633            -91.387335   \n",
       "\n",
       "   Frequency_498dot861  Frequency_499dot1865  Frequency_499dot5119  \\\n",
       "0           -90.199369            -87.116829            -88.726635   \n",
       "1           -91.703702            -94.641164            -90.733663   \n",
       "2           -91.192905            -91.401812            -91.905812   \n",
       "3           -90.758625            -88.137099            -89.833695   \n",
       "4           -93.815508            -93.235216            -92.409103   \n",
       "\n",
       "   Frequency_499dot8373  Label  \n",
       "0            -90.726685      0  \n",
       "1            -89.704103      0  \n",
       "2            -86.226784      0  \n",
       "3            -89.888380      0  \n",
       "4            -93.528927      0  \n",
       "\n",
       "[5 rows x 1140 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# library for GA\n",
    "import random\n",
    "\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "# library for RF\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from seaborn import violinplot\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# read data\n",
    "spectrum_data = pd.read_excel('./spectrum_data/Nothing_Mine_CEandRock.xlsx',  sep = ',', header = 0)\n",
    "# remove freqs prior to 129\n",
    "spectrum_data_new = spectrum_data.iloc[:, 400:1539]\n",
    "\n",
    "\n",
    "# df.insert(loc=idx, column='A', value=new_col)\n",
    "spectrum_data_new.insert(loc = 0, column = 'Signal Path', value = spectrum_data.iloc[:, 0])\n",
    "spectrum_data_new[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set algorithm parameters\n",
    "\n",
    "def run_GA(NUM_TREES, IND_SIZE, POP_SIZE, CX_RATE = 0.8):\n",
    "    \"\"\"\n",
    "    NUM_TREES is the number of trees the random forest model pro\n",
    "    \"\"\"    \n",
    "    MUTATE_RATE = 1.0/IND_SIZE \n",
    "    \n",
    "    \n",
    "    \n",
    "    # prepare data: for each label, split the data into 25% test and 75 train\n",
    "    raw = spectrum_data_new.values\n",
    "\n",
    "    X_0 = raw[0:100, 0:1139]\n",
    "    y_0 = raw[0:100, 1139]\n",
    "\n",
    "    X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(X_0, y_0, test_size=0.25, random_state=random.randint(0,5000))\n",
    "\n",
    "    X_1 = raw[100:200, 0:1139]\n",
    "    y_1 = raw[100:200, 1139]\n",
    "\n",
    "    X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, y_1, test_size=0.25, random_state=random.randint(0,5000))\n",
    "\n",
    "    X_2 = raw[200:300, 0:1139]\n",
    "    y_2 = raw[200:300, 1139]\n",
    "\n",
    "    X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.25, random_state=random.randint(0,5000))\n",
    "\n",
    "    y_test = np.concatenate((y_test_0, y_test_1, y_test_2), axis=0)\n",
    "    y_train = np.concatenate((y_train_0, y_train_1, y_train_2), axis=0)\n",
    "    X_test = np.concatenate((X_test_0, X_test_1, X_test_2), axis=0)\n",
    "    X_train = np.concatenate((X_train_0, X_train_1, X_train_2), axis=0)\n",
    "    \n",
    "    # Feature Scaling\n",
    "    end = 1139\n",
    "    scaler = StandardScaler()\n",
    "    X_train[:, 1:end] = scaler.fit_transform(X_train[:, 1:end])   # Fit to data, then transform it. Fit means Compute the mean and std to be used for later scaling.\n",
    "    X_test[:, 1:end] = scaler.transform(X_test[:, 1:end]) # Perform standardization by centering and scaling\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators= NUM_TREES) # create a random forest with NUM_TREES = 20 \n",
    "    model.fit(X_train, y_train) # train the model\n",
    "    estimators = model.estimators_ # get all the trees\n",
    "    \n",
    "    # implement individual\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "    # implement functions for initialize population and create individual\n",
    "    toolbox = base.Toolbox() # create a toolbox of operators for our GA algorithm\n",
    "    toolbox.register(\"indices\", random.sample, range(NUM_TREES), NUM_TREES) # this is a helper function for creating\n",
    "                                                                            # each individual\n",
    "    toolbox.register(\"individual\", tools.initIterate, creator.Individual,   # this is the function for creating an \n",
    "                     toolbox.indices)                                       # individual\n",
    "\n",
    "\n",
    "    #toolbox.individual()  # a test \n",
    "\n",
    "    # implement function for creating a population\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual, n = POP_SIZE)\n",
    "\n",
    "    #toolbox.population()  # a test\n",
    "    \n",
    "    def sub_rf_predict(sub_rf, X_test):\n",
    "        \"\"\"\n",
    "        return the predict result using the sub_rf and X_test data;\n",
    "        the rule is that predict result(labels) with the maximum number of votes wins.\n",
    "        \"\"\"\n",
    "        predict_results = []\n",
    "        for tree in sub_rf:\n",
    "            prediction = tree.predict(X_test)\n",
    "            # record prediction result for a tree\n",
    "            predict_results.append(prediction)\n",
    "\n",
    "        # compute the vote_result, i.e. the final result\n",
    "        y_predict = [0]*len(X_test)\n",
    "        for idx in range(len(X_test)):\n",
    "            # for each test data\n",
    "            # create a vote result\n",
    "            v_result = vote_result()\n",
    "            for predict_tree in predict_results:\n",
    "                v_result[predict_tree[idx]] += 1\n",
    "\n",
    "            # final result\n",
    "            y_predict[idx] = keywithmaxval(v_result)\n",
    "\n",
    "        return  np.array(y_predict, dtype = float)\n",
    "\n",
    "    # helper function\n",
    "    y_set = set(y_test).union(y_train)\n",
    "    def vote_result():\n",
    "        result = {}\n",
    "        for k in y_set:\n",
    "            result[k] = 0\n",
    "        return result\n",
    "\n",
    "    def keywithmaxval(d):\n",
    "        \"\"\" a) create a list of the dict's keys and values; \n",
    "        b) return the key with the max value\"\"\"  \n",
    "        v=list(d.values())\n",
    "        k=list(d.keys())\n",
    "        return k[v.index(max(v))]\n",
    "    \n",
    "    \n",
    "    def evaluate(individual):\n",
    "        # return the accuracy on the test data\n",
    "        sub_random_forest = []\n",
    "        for tree_idx in individual[0: IND_SIZE]:\n",
    "            sub_random_forest.append(estimators[tree_idx])\n",
    "\n",
    "        predict_sub_trees = sub_rf_predict(sub_random_forest, X_test)\n",
    "        # print(predict_sub_trees.__repr__())\n",
    "        # score = precision_score(y_test, predict_sub_trees, average = 'macro')\n",
    "        cf_matrix = evaluate_confusion_matrix(individual)\n",
    "        \n",
    "        pseudo_acc_case_rate = cf_matrix[1, 1] / np.sum(cf_matrix)\n",
    "        bad_case_rate = (cf_matrix[1, 0] + cf_matrix[1, 2]) / np.sum(cf_matrix)\n",
    "        undesired_case_rate = (cf_matrix[0, 1] + cf_matrix[2, 1]) / np.sum(cf_matrix)\n",
    "        \n",
    "        # give accuracy more weight\n",
    "        score = (0.4 * pseudo_acc_case_rate - 0.4 * bad_case_rate - 0.2 * undesired_case_rate) # the max score is 1 and the min score is 0.\n",
    "        return  score,  # must return an tuple!!!!\n",
    "    \n",
    "    def evaluate_confusion_matrix(individual):\n",
    "        # return the confusion matrix of a model\n",
    "        sub_random_forest = []\n",
    "        for tree_idx in individual[0: IND_SIZE]:\n",
    "            sub_random_forest.append(estimators[tree_idx])  \n",
    "\n",
    "        predict_sub_trees = sub_rf_predict(sub_random_forest, X_test)\n",
    "        cf_matrix = confusion_matrix(y_test, predict_sub_trees)\n",
    "        return  cf_matrix \n",
    "\n",
    "    \n",
    "    \n",
    "    # implement mutation operator\n",
    "    mutation_op = tools.mutShuffleIndexes\n",
    "    \n",
    "    \n",
    "    # implement crossover\n",
    "    def crossover_op(ind1, ind2):\n",
    "        # only cross over the first IND_SIZE elements in the individual in place\n",
    "        crossover_idx = random.randint(0, IND_SIZE - 2)\n",
    "        # print(crossover_idx)\n",
    "        temp = toolbox.clone(ind1[crossover_idx + 1: IND_SIZE])\n",
    "        ind1[crossover_idx + 1: IND_SIZE] = ind2[crossover_idx + 1: IND_SIZE]\n",
    "        ind2[crossover_idx + 1: IND_SIZE] = temp\n",
    "        return (ind1, ind2)\n",
    "    \n",
    "    # implement selection operator\n",
    "    selection_op = tools.selTournament\n",
    "    \n",
    "    \n",
    "    # register everything in our toolbox\n",
    "    toolbox.register(\"mate\", crossover_op)\n",
    "    toolbox.register(\"mutate\", mutation_op, indpb = MUTATE_RATE)\n",
    "    toolbox.register(\"select\", selection_op, tournsize=3)\n",
    "    toolbox.register(\"evaluate\", evaluate)\n",
    "    \n",
    "    \n",
    "    h_fame = tools.HallOfFame(100) # keep track of the first 100 best individuals and store them in h_fame\n",
    "\n",
    "    pop = toolbox.population()\n",
    "    final_pop = algorithms.eaSimple(pop, toolbox, cxpb = CX_RATE, mutpb=MUTATE_RATE, ngen=1000, \n",
    "                                    stats = None, halloffame = h_fame, verbose = False)\n",
    "    \n",
    "    # accuracy_of_the_best_individual = evaluate(h_fame[0])\n",
    "    # accuracy_of_the_whole_trees_model = accuracy_score(y_test, model.predict(X_test))\n",
    "    cf_matrix_RF_model = confusion_matrix(y_test, model.predict(X_test))\n",
    "    cf_matrix_GA_RF_model = evaluate_confusion_matrix(h_fame[0])\n",
    "    \n",
    "    return cf_matrix_GA_RF_model, cf_matrix_RF_model, evaluate_confusion_matrix, h_fame, estimators\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_model_performance(C):\n",
    "    \"\"\"\n",
    "    C is a confusion matrix\n",
    "    accuracy, sensitivity, specificity: the higher the better\n",
    "    FP_rate: the lower the better\n",
    "    \n",
    "    Now, only compute accuracy\n",
    "    \"\"\"\n",
    "    accuracy = (C[0,0] + C[1, 1] + C[2, 2]) / np.sum(C)\n",
    "    sensitivity = 0\n",
    "    specificity = 0 \n",
    "    FP_rate = 0\n",
    "    \n",
    "    cf_matrix = C\n",
    "    pseudo_acc_case_rate = cf_matrix[1, 1] / np.sum(cf_matrix)\n",
    "    bad_case_rate = (cf_matrix[1, 0] + cf_matrix[1, 2]) / np.sum(cf_matrix)\n",
    "    undesired_case_rate = (cf_matrix[0, 1] + cf_matrix[2, 1]) / np.sum(cf_matrix)\n",
    "    \n",
    "    left_diag_case_rate = (cf_matrix[0, 0] + cf_matrix[2, 2]) / np.sum(cf_matrix)\n",
    "    right_diag_case_rate = (cf_matrix[0, 2] + cf_matrix[2, 0]) / np.sum(cf_matrix)\n",
    "        # give accuracy more weight\n",
    "    score = (0.4 * pseudo_acc_case_rate - 0.4 * bad_case_rate - 0.2 * undesired_case_rate)\n",
    "    \n",
    "    return accuracy, sensitivity, specificity, FP_rate, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_trees =  100\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "num_trees = 100\n",
    "GA_accuracy_result = []\n",
    "RF_accuracy_result = []\n",
    "\n",
    "GA_sensitivity_result = []\n",
    "RF_sensitivity_result = []\n",
    "\n",
    "GA_specificity_result = []\n",
    "RF_specificity_result = []\n",
    "\n",
    "GA_FP_rate_result = []\n",
    "RF_FP_rate_result = []\n",
    "\n",
    "confusion_matrices_list_GA_RF = []\n",
    "h_fame_list = []\n",
    "GA_RF_model_list = []\n",
    "\n",
    "GA_score_list = []\n",
    "RF_score_list = []\n",
    "\n",
    "print('num_trees = ', num_trees)\n",
    "for i in range(100):  # run the experiment 300 times\n",
    "    print(i)\n",
    "    cf_matrix_GA_RF_model, cf_matrix_RF_model, evaluate_confusion_matrix, h_fame, estimators = run_GA(num_trees, 10, 30)\n",
    "    \n",
    "    GA_accuracy, GA_sensitivity, GA_specificity, GA_FP_rate, GA_score = measure_model_performance(cf_matrix_GA_RF_model)\n",
    "    RF_accuracy, RF_sensitivity, RF_specificity, RF_FP_rate, RF_score = measure_model_performance(cf_matrix_RF_model)\n",
    "\n",
    "    GA_accuracy_result.append(GA_accuracy)\n",
    "    RF_accuracy_result.append(RF_accuracy)\n",
    "\n",
    "    GA_sensitivity_result.append(GA_sensitivity)\n",
    "    RF_sensitivity_result.append(RF_sensitivity)\n",
    "\n",
    "    GA_specificity_result.append(GA_specificity)\n",
    "    RF_specificity_result.append(RF_specificity)\n",
    "\n",
    "    GA_FP_rate_result.append(GA_FP_rate)\n",
    "    RF_FP_rate_result.append(RF_FP_rate)\n",
    "    \n",
    "    confusion_matrices_list_GA_RF.append(cf_matrix_GA_RF_model)\n",
    "    GA_RF_model_list.append(estimators)\n",
    "    \n",
    "    GA_score_list.append(GA_score)\n",
    "    RF_score_list.append(RF_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result():\n",
    "    print(\"mean accuracy = \",  np.mean(GA_accuracy_result))\n",
    "    print(\"std accuracy = \", np.std(GA_accuracy_result))\n",
    "    print(\"Max accuracy = \", np.max(GA_accuracy_result))\n",
    "    print(\"confusion Matrix for model with max accuracy is \\n\", confusion_matrices_list_GA_RF[np.argmax(GA_accuracy_result)])\n",
    "    print(\"Max score = \", np.max(GA_score_list))\n",
    "    print(\"confusion Matrix for model with max score is \\n\", confusion_matrices_list_GA_RF[np.argmax(GA_score_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.6044\n",
      "std accuracy =  0.04490206627267341\n",
      "Max accuracy =  0.72\n",
      "confusion Matrix for model with max accuracy is \n",
      " [[18  2  5]\n",
      " [ 4 19  2]\n",
      " [ 5  3 17]]\n",
      "Max score =  0.10933333333333334\n",
      "confusion Matrix for model with max score is \n",
      " [[14  5  6]\n",
      " [ 0 25  0]\n",
      " [ 9  4 12]]\n"
     ]
    }
   ],
   "source": [
    "show_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = 2/15\n",
    "min_score = -1/5\n",
    "def normalize_score(scores, max_score, min_score):\n",
    "    np_scores = np.array(scores)\n",
    "    return (np_scores - min_score)/(max_score - min_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.768, 0.808, 0.768, 0.768, 0.744, 0.8  , 0.704, 0.728, 0.808,\n",
       "       0.84 , 0.792, 0.832, 0.696, 0.928, 0.776, 0.704, 0.768, 0.776,\n",
       "       0.792, 0.856, 0.816, 0.68 , 0.792, 0.832, 0.848, 0.8  , 0.816,\n",
       "       0.808, 0.792, 0.736, 0.68 , 0.8  , 0.736, 0.72 , 0.848, 0.776,\n",
       "       0.728, 0.776, 0.784, 0.712, 0.768, 0.768, 0.696, 0.816, 0.792,\n",
       "       0.808, 0.736, 0.84 , 0.728, 0.856, 0.792, 0.704, 0.792, 0.744,\n",
       "       0.848, 0.832, 0.792, 0.808, 0.736, 0.784, 0.72 , 0.672, 0.776,\n",
       "       0.864, 0.672, 0.792, 0.856, 0.832, 0.728, 0.88 , 0.712, 0.848,\n",
       "       0.808, 0.848, 0.776, 0.784, 0.824, 0.768, 0.864, 0.68 , 0.792,\n",
       "       0.8  , 0.768, 0.8  , 0.8  , 0.76 , 0.808, 0.784, 0.784, 0.792,\n",
       "       0.76 , 0.856, 0.8  , 0.792, 0.768, 0.848, 0.856, 0.784, 0.8  ,\n",
       "       0.768])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GA_norm_score = normalize_score(GA_score_list, max_score, min_score)\n",
    "GA_norm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.416, 0.464, 0.408, 0.24 , 0.496, 0.52 , 0.256, 0.392, 0.568,\n",
       "       0.448, 0.472, 0.544, 0.392, 0.544, 0.4  , 0.424, 0.408, 0.352,\n",
       "       0.368, 0.392, 0.328, 0.312, 0.376, 0.496, 0.312, 0.432, 0.36 ,\n",
       "       0.264, 0.44 , 0.424, 0.44 , 0.504, 0.416, 0.296, 0.472, 0.368,\n",
       "       0.264, 0.464, 0.384, 0.4  , 0.328, 0.32 , 0.288, 0.448, 0.512,\n",
       "       0.296, 0.416, 0.472, 0.416, 0.408, 0.304, 0.392, 0.488, 0.352,\n",
       "       0.496, 0.376, 0.32 , 0.408, 0.448, 0.424, 0.336, 0.224, 0.52 ,\n",
       "       0.456, 0.352, 0.32 , 0.384, 0.44 , 0.408, 0.32 , 0.304, 0.456,\n",
       "       0.464, 0.592, 0.328, 0.504, 0.568, 0.392, 0.448, 0.344, 0.44 ,\n",
       "       0.472, 0.416, 0.552, 0.496, 0.392, 0.384, 0.32 , 0.424, 0.24 ,\n",
       "       0.352, 0.336, 0.432, 0.488, 0.416, 0.48 , 0.528, 0.424, 0.408,\n",
       "       0.536])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_norm_score = normalize_score(RF_score_list, max_score, min_score)\n",
    "RF_norm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
