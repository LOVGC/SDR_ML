{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the features by using the standard scaler\n",
    "# algorithm parameter:\n",
    "#      100 total trees in RF\n",
    "#      select 10 trees by GA\n",
    "\n",
    "\n",
    " # run the experiment 300 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library for GA\n",
    "import random\n",
    "\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "# library for RF\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from seaborn import violinplot\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_data = pd.read_excel('./spectrum_data/Nothing_Mine_CEandRock.xlsx',  sep = ',', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Signal_Path</th>\n",
       "      <th>Frequency_0</th>\n",
       "      <th>Frequency_0dot32541</th>\n",
       "      <th>Frequency_0dot65083</th>\n",
       "      <th>Frequency_0dot97624</th>\n",
       "      <th>Frequency_1dot3017</th>\n",
       "      <th>Frequency_1dot6271</th>\n",
       "      <th>Frequency_1dot9525</th>\n",
       "      <th>Frequency_2dot2779</th>\n",
       "      <th>Frequency_2dot6033</th>\n",
       "      <th>...</th>\n",
       "      <th>Frequency_497dot234</th>\n",
       "      <th>Frequency_497dot5594</th>\n",
       "      <th>Frequency_497dot8848</th>\n",
       "      <th>Frequency_498dot2102</th>\n",
       "      <th>Frequency_498dot5356</th>\n",
       "      <th>Frequency_498dot861</th>\n",
       "      <th>Frequency_499dot1865</th>\n",
       "      <th>Frequency_499dot5119</th>\n",
       "      <th>Frequency_499dot8373</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-16.746793</td>\n",
       "      <td>-20.676797</td>\n",
       "      <td>-31.824529</td>\n",
       "      <td>-33.595664</td>\n",
       "      <td>-35.576217</td>\n",
       "      <td>-35.434632</td>\n",
       "      <td>-36.515813</td>\n",
       "      <td>-38.387189</td>\n",
       "      <td>-38.728927</td>\n",
       "      <td>...</td>\n",
       "      <td>-86.637317</td>\n",
       "      <td>-86.343540</td>\n",
       "      <td>-86.970514</td>\n",
       "      <td>-87.039263</td>\n",
       "      <td>-88.502441</td>\n",
       "      <td>-90.199369</td>\n",
       "      <td>-87.116829</td>\n",
       "      <td>-88.726635</td>\n",
       "      <td>-90.726685</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-4.551514</td>\n",
       "      <td>-7.421589</td>\n",
       "      <td>-27.810436</td>\n",
       "      <td>-31.355778</td>\n",
       "      <td>-37.968985</td>\n",
       "      <td>-41.496863</td>\n",
       "      <td>-40.665835</td>\n",
       "      <td>-41.751791</td>\n",
       "      <td>-45.158375</td>\n",
       "      <td>...</td>\n",
       "      <td>-92.337580</td>\n",
       "      <td>-94.363767</td>\n",
       "      <td>-92.113655</td>\n",
       "      <td>-91.933969</td>\n",
       "      <td>-91.717233</td>\n",
       "      <td>-91.703702</td>\n",
       "      <td>-94.641164</td>\n",
       "      <td>-90.733663</td>\n",
       "      <td>-89.704103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-8.464251</td>\n",
       "      <td>-11.391572</td>\n",
       "      <td>-31.498198</td>\n",
       "      <td>-38.491415</td>\n",
       "      <td>-45.693272</td>\n",
       "      <td>-41.769994</td>\n",
       "      <td>-39.504399</td>\n",
       "      <td>-40.434299</td>\n",
       "      <td>-43.019136</td>\n",
       "      <td>...</td>\n",
       "      <td>-90.403409</td>\n",
       "      <td>-91.020674</td>\n",
       "      <td>-88.187210</td>\n",
       "      <td>-85.616805</td>\n",
       "      <td>-86.914083</td>\n",
       "      <td>-91.192905</td>\n",
       "      <td>-91.401812</td>\n",
       "      <td>-91.905812</td>\n",
       "      <td>-86.226784</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-5.957897</td>\n",
       "      <td>-8.926523</td>\n",
       "      <td>-36.362773</td>\n",
       "      <td>-38.174161</td>\n",
       "      <td>-40.979502</td>\n",
       "      <td>-43.905112</td>\n",
       "      <td>-46.415447</td>\n",
       "      <td>-41.430853</td>\n",
       "      <td>-42.829122</td>\n",
       "      <td>...</td>\n",
       "      <td>-90.557058</td>\n",
       "      <td>-91.756146</td>\n",
       "      <td>-89.087595</td>\n",
       "      <td>-90.093507</td>\n",
       "      <td>-89.855050</td>\n",
       "      <td>-90.758625</td>\n",
       "      <td>-88.137099</td>\n",
       "      <td>-89.833695</td>\n",
       "      <td>-89.888380</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-5.197722</td>\n",
       "      <td>-8.236918</td>\n",
       "      <td>-35.767897</td>\n",
       "      <td>-39.269133</td>\n",
       "      <td>-43.522638</td>\n",
       "      <td>-47.068337</td>\n",
       "      <td>-50.534088</td>\n",
       "      <td>-51.865788</td>\n",
       "      <td>-50.955593</td>\n",
       "      <td>...</td>\n",
       "      <td>-91.405036</td>\n",
       "      <td>-90.592510</td>\n",
       "      <td>-91.839187</td>\n",
       "      <td>-93.906633</td>\n",
       "      <td>-91.387335</td>\n",
       "      <td>-93.815508</td>\n",
       "      <td>-93.235216</td>\n",
       "      <td>-92.409103</td>\n",
       "      <td>-93.528927</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1539 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Signal_Path  Frequency_0  Frequency_0dot32541  Frequency_0dot65083  \\\n",
       "0            1   -16.746793           -20.676797           -31.824529   \n",
       "1            1    -4.551514            -7.421589           -27.810436   \n",
       "2            1    -8.464251           -11.391572           -31.498198   \n",
       "3            1    -5.957897            -8.926523           -36.362773   \n",
       "4            1    -5.197722            -8.236918           -35.767897   \n",
       "\n",
       "   Frequency_0dot97624  Frequency_1dot3017  Frequency_1dot6271  \\\n",
       "0           -33.595664          -35.576217          -35.434632   \n",
       "1           -31.355778          -37.968985          -41.496863   \n",
       "2           -38.491415          -45.693272          -41.769994   \n",
       "3           -38.174161          -40.979502          -43.905112   \n",
       "4           -39.269133          -43.522638          -47.068337   \n",
       "\n",
       "   Frequency_1dot9525  Frequency_2dot2779  Frequency_2dot6033  ...  \\\n",
       "0          -36.515813          -38.387189          -38.728927  ...   \n",
       "1          -40.665835          -41.751791          -45.158375  ...   \n",
       "2          -39.504399          -40.434299          -43.019136  ...   \n",
       "3          -46.415447          -41.430853          -42.829122  ...   \n",
       "4          -50.534088          -51.865788          -50.955593  ...   \n",
       "\n",
       "   Frequency_497dot234  Frequency_497dot5594  Frequency_497dot8848  \\\n",
       "0           -86.637317            -86.343540            -86.970514   \n",
       "1           -92.337580            -94.363767            -92.113655   \n",
       "2           -90.403409            -91.020674            -88.187210   \n",
       "3           -90.557058            -91.756146            -89.087595   \n",
       "4           -91.405036            -90.592510            -91.839187   \n",
       "\n",
       "   Frequency_498dot2102  Frequency_498dot5356  Frequency_498dot861  \\\n",
       "0            -87.039263            -88.502441           -90.199369   \n",
       "1            -91.933969            -91.717233           -91.703702   \n",
       "2            -85.616805            -86.914083           -91.192905   \n",
       "3            -90.093507            -89.855050           -90.758625   \n",
       "4            -93.906633            -91.387335           -93.815508   \n",
       "\n",
       "   Frequency_499dot1865  Frequency_499dot5119  Frequency_499dot8373  Label  \n",
       "0            -87.116829            -88.726635            -90.726685      0  \n",
       "1            -94.641164            -90.733663            -89.704103      0  \n",
       "2            -91.401812            -91.905812            -86.226784      0  \n",
       "3            -88.137099            -89.833695            -89.888380      0  \n",
       "4            -93.235216            -92.409103            -93.528927      0  \n",
       "\n",
       "[5 rows x 1539 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrum_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set algorithm parameters\n",
    "\n",
    "def run_GA(NUM_TREES, IND_SIZE, POP_SIZE, CX_RATE = 0.8):\n",
    "    \"\"\"\n",
    "    NUM_TREES is the number of trees the random forest model pro\n",
    "    \"\"\"    \n",
    "    MUTATE_RATE = 1.0/IND_SIZE \n",
    "    \n",
    "    \n",
    "    \n",
    "    # prepare data\n",
    "   \n",
    "    raw = spectrum_data.values\n",
    "\n",
    "    X = raw[:, 0:1538]\n",
    "    y = raw[:, 1538]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=random.randint(0,5000))\n",
    "    \n",
    "    # Feature Scaling\n",
    "    end = 1539\n",
    "    scaler = StandardScaler()\n",
    "    X_train[:, 1:end] = scaler.fit_transform(X_train[:, 1:end])   # Fit to data, then transform it. Fit means Compute the mean and std to be used for later scaling.\n",
    "    X_test[:, 1:end] = scaler.transform(X_test[:, 1:end]) # Perform standardization by centering and scaling\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators= NUM_TREES) # create a random forest with NUM_TREES = 20 \n",
    "    model.fit(X_train, y_train) # train the model\n",
    "    estimators = model.estimators_ # get all the trees\n",
    "    \n",
    "    # implement individual\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "    # implement functions for initialize population and create individual\n",
    "    toolbox = base.Toolbox() # create a toolbox of operators for our GA algorithm\n",
    "    toolbox.register(\"indices\", random.sample, range(NUM_TREES), NUM_TREES) # this is a helper function for creating\n",
    "                                                                            # each individual\n",
    "    toolbox.register(\"individual\", tools.initIterate, creator.Individual,   # this is the function for creating an \n",
    "                     toolbox.indices)                                       # individual\n",
    "\n",
    "\n",
    "    #toolbox.individual()  # a test \n",
    "\n",
    "    # implement function for creating a population\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual, n = POP_SIZE)\n",
    "\n",
    "    #toolbox.population()  # a test\n",
    "    \n",
    "    def sub_rf_predict(sub_rf, X_test):\n",
    "        \"\"\"\n",
    "        return the predict result using the sub_rf and X_test data;\n",
    "        the rule is that predict result(labels) with the maximum number of votes wins.\n",
    "        \"\"\"\n",
    "        predict_results = []\n",
    "        for tree in sub_rf:\n",
    "            prediction = tree.predict(X_test)\n",
    "            # record prediction result for a tree\n",
    "            predict_results.append(prediction)\n",
    "\n",
    "        # compute the vote_result, i.e. the final result\n",
    "        y_predict = [0]*len(X_test)\n",
    "        for idx in range(len(X_test)):\n",
    "            # for each test data\n",
    "            # create a vote result\n",
    "            v_result = vote_result()\n",
    "            for predict_tree in predict_results:\n",
    "                v_result[predict_tree[idx]] += 1\n",
    "\n",
    "            # final result\n",
    "            y_predict[idx] = keywithmaxval(v_result)\n",
    "\n",
    "        return  np.array(y_predict, dtype = float)\n",
    "\n",
    "    # helper function\n",
    "    y_set = set(y_test).union(y_train)\n",
    "    def vote_result():\n",
    "        result = {}\n",
    "        for k in y_set:\n",
    "            result[k] = 0\n",
    "        return result\n",
    "\n",
    "    def keywithmaxval(d):\n",
    "        \"\"\" a) create a list of the dict's keys and values; \n",
    "        b) return the key with the max value\"\"\"  \n",
    "        v=list(d.values())\n",
    "        k=list(d.keys())\n",
    "        return k[v.index(max(v))]\n",
    "    \n",
    "    \n",
    "    #  modified fitness function\n",
    "    def evaluate(individual):\n",
    "        # return the accuracy on the test data\n",
    "        sub_random_forest = []\n",
    "        for tree_idx in individual[0: IND_SIZE]:\n",
    "            sub_random_forest.append(estimators[tree_idx])\n",
    "\n",
    "        predict_sub_trees = sub_rf_predict(sub_random_forest, X_test)\n",
    "        # print(predict_sub_trees.__repr__())\n",
    "        # score = precision_score(y_test, predict_sub_trees, average = 'macro')\n",
    "        cf_matrix = evaluate_confusion_matrix(individual)\n",
    "        \n",
    "        pseudo_acc_case_rate = cf_matrix[1, 1] / np.sum(cf_matrix)\n",
    "        bad_case_rate = (cf_matrix[1, 0] + cf_matrix[1, 2]) / np.sum(cf_matrix)\n",
    "        undesired_case_rate = (cf_matrix[0, 1] + cf_matrix[2, 1]) / np.sum(cf_matrix)\n",
    "        \n",
    "        # give accuracy more weight\n",
    "        score = 0.4 * pseudo_acc_case_rate - 0.4 * bad_case_rate - 0.2 * undesired_case_rate\n",
    "        return  score,  # must return an tuple!!!!\n",
    "    \n",
    "    def evaluate_confusion_matrix(individual):\n",
    "        # return the confusion matrix of a model\n",
    "        sub_random_forest = []\n",
    "        for tree_idx in individual[0: IND_SIZE]:\n",
    "            sub_random_forest.append(estimators[tree_idx])\n",
    "\n",
    "        predict_sub_trees = sub_rf_predict(sub_random_forest, X_test)\n",
    "        cf_matrix = confusion_matrix(y_test, predict_sub_trees)\n",
    "        return  cf_matrix \n",
    "\n",
    "    \n",
    "    \n",
    "    # implement mutation operator\n",
    "    mutation_op = tools.mutShuffleIndexes\n",
    "    \n",
    "    \n",
    "    # implement crossover\n",
    "    def crossover_op(ind1, ind2):\n",
    "        # only cross over the first IND_SIZE elements in the individual in place\n",
    "        crossover_idx = random.randint(0, IND_SIZE - 2)\n",
    "        # print(crossover_idx)\n",
    "        temp = toolbox.clone(ind1[crossover_idx + 1: IND_SIZE])\n",
    "        ind1[crossover_idx + 1: IND_SIZE] = ind2[crossover_idx + 1: IND_SIZE]\n",
    "        ind2[crossover_idx + 1: IND_SIZE] = temp\n",
    "        return (ind1, ind2)\n",
    "    \n",
    "    # implement selection operator\n",
    "    selection_op = tools.selTournament\n",
    "    \n",
    "    \n",
    "    # register everything in our toolbox\n",
    "    toolbox.register(\"mate\", crossover_op)\n",
    "    toolbox.register(\"mutate\", mutation_op, indpb = MUTATE_RATE)\n",
    "    toolbox.register(\"select\", selection_op, tournsize=3)\n",
    "    toolbox.register(\"evaluate\", evaluate)\n",
    "    \n",
    "    \n",
    "    h_fame = tools.HallOfFame(100) # keep track of the first 100 best individuals and store them in h_fame\n",
    "\n",
    "    pop = toolbox.population()\n",
    "    final_pop = algorithms.eaSimple(pop, toolbox, cxpb = CX_RATE, mutpb=MUTATE_RATE, ngen=1000, \n",
    "                                    stats = None, halloffame = h_fame, verbose = False)\n",
    "    \n",
    "    # accuracy_of_the_best_individual = evaluate(h_fame[0])\n",
    "    # accuracy_of_the_whole_trees_model = accuracy_score(y_test, model.predict(X_test))\n",
    "    cf_matrix_RF_model = confusion_matrix(y_test, model.predict(X_test))\n",
    "    cf_matrix_GA_RF_model = evaluate_confusion_matrix(h_fame[0])\n",
    "    \n",
    "    return cf_matrix_GA_RF_model, cf_matrix_RF_model, evaluate_confusion_matrix, h_fame, estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_model_performance(C):\n",
    "    \"\"\"\n",
    "    C is a confusion matrix\n",
    "    accuracy, sensitivity, specificity: the higher the better\n",
    "    FP_rate: the lower the better\n",
    "    \n",
    "    Now, only compute accuracy\n",
    "    \"\"\"\n",
    "    accuracy = (C[0,0] + C[1, 1] + C[2, 2]) / np.sum(C)\n",
    "    sensitivity = 0\n",
    "    specificity = 0 \n",
    "    FP_rate = 0\n",
    "    \n",
    "    cf_matrix = C\n",
    "    pseudo_acc_case_rate = cf_matrix[1, 1] / np.sum(cf_matrix)\n",
    "    bad_case_rate = (cf_matrix[1, 0] + cf_matrix[1, 2]) / np.sum(cf_matrix)\n",
    "    undesired_case_rate = (cf_matrix[0, 1] + cf_matrix[2, 1]) / np.sum(cf_matrix)\n",
    "    \n",
    "    left_diag_case_rate = (cf_matrix[0, 0] + cf_matrix[2, 2]) / np.sum(cf_matrix)\n",
    "    right_diag_case_rate = (cf_matrix[0, 2] + cf_matrix[2, 0]) / np.sum(cf_matrix)\n",
    "        # give accuracy more weight\n",
    "    performance = 0.3 * pseudo_acc_case_rate - 0.3 * bad_case_rate - 0.2 * undesired_case_rate + 0.2 * 0.8 * left_diag_case_rate + 0.2 * 0.2 * right_diag_case_rate\n",
    "    \n",
    "    return accuracy, sensitivity, specificity, FP_rate, performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_trees =  100\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "num_trees = 100\n",
    "GA_accuracy_result = []\n",
    "RF_accuracy_result = []\n",
    "\n",
    "GA_sensitivity_result = []\n",
    "RF_sensitivity_result = []\n",
    "\n",
    "GA_specificity_result = []\n",
    "RF_specificity_result = []\n",
    "\n",
    "GA_FP_rate_result = []\n",
    "RF_FP_rate_result = []\n",
    "\n",
    "confusion_matrices_list_GA_RF = []\n",
    "h_fame_list = []\n",
    "GA_RF_model_list = []\n",
    "\n",
    "GA_score_list = []\n",
    "\n",
    "print('num_trees = ', num_trees)\n",
    "for i in range(300):  # run the experiment 300 times\n",
    "    print(i)\n",
    "    cf_matrix_GA_RF_model, cf_matrix_RF_model, evaluate_confusion_matrix, h_fame, estimators = run_GA(num_trees, 10, 30)\n",
    "    \n",
    "    GA_accuracy, GA_sensitivity, GA_specificity, GA_FP_rate, GA_score = measure_model_performance(cf_matrix_GA_RF_model)\n",
    "    RF_accuracy, RF_sensitivity, RF_specificity, RF_FP_rate, RF_score = measure_model_performance(cf_matrix_RF_model)\n",
    "\n",
    "    GA_accuracy_result.append(GA_accuracy)\n",
    "    RF_accuracy_result.append(RF_accuracy)\n",
    "\n",
    "    GA_sensitivity_result.append(GA_sensitivity)\n",
    "    RF_sensitivity_result.append(RF_sensitivity)\n",
    "\n",
    "    GA_specificity_result.append(GA_specificity)\n",
    "    RF_specificity_result.append(RF_specificity)\n",
    "\n",
    "    GA_FP_rate_result.append(GA_FP_rate)\n",
    "    RF_FP_rate_result.append(RF_FP_rate)\n",
    "    \n",
    "    confusion_matrices_list_GA_RF.append(cf_matrix_GA_RF_model)\n",
    "    GA_RF_model_list.append(estimators)\n",
    "    \n",
    "    GA_score_list.append(GA_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result():\n",
    "    print(\"mean accuracy = \",  np.mean(GA_accuracy_result))\n",
    "    print(\"std accuracy = \", np.std(GA_accuracy_result))\n",
    "    print(\"Max accuracy = \", np.max(GA_accuracy_result))\n",
    "    print(\"confusion Matrix for model with max accuracy is \\n\", confusion_matrices_list_GA_RF[np.argmax(GA_accuracy_result)])\n",
    "    print(\"Max score = \", np.max(GA_score_list))\n",
    "    print(\"confusion Matrix for model with max score is \\n\", confusion_matrices_list_GA_RF[np.argmax(GA_score_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.6590222222222222\n",
      "std accuracy =  0.050849883158999985\n",
      "Max accuracy =  0.8\n",
      "confusion Matrix for model with max accuracy is \n",
      " [[19  5  4]\n",
      " [ 0 23  1]\n",
      " [ 2  3 18]]\n",
      "Max score =  0.16\n",
      "confusion Matrix for model with max score is \n",
      " [[19  0  7]\n",
      " [ 0 23  1]\n",
      " [ 7  3 15]]\n"
     ]
    }
   ],
   "source": [
    "show_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
